#!/usr/bin/env python3
"""
Scirate Discord Bot (å®Œå…¨ç‰ˆ)
Scirateã®quant-phãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰ã€scitesæ•°ä¸Šä½10ä»¶ã®è«–æ–‡ã‚’AIè¦ç´„ä»˜ãã§Discordã«æŠ•ç¨¿

ä½¿ã„æ–¹:
1. å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install requests beautifulsoup4
2. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ: python scirate_discord_bot.py
"""

import requests
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from datetime import datetime
import time
from typing import List, Dict
import re
import os

# ===== è¨­å®šï¼ˆã“ã“ã‚’ç·¨é›†ã—ã¦ãã ã•ã„ï¼‰ =====
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼ˆGitHub Actionsç”¨ï¼‰ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL', "https://discordapp.com/api/webhooks/1440300959053119538/uMebZxptK0QGMDrGnicpomGxeil_dSUofXY_H10bUdst1utNlPaAI1rHeTEfCXf1ki7s")
ANTHROPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY', "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")
ARXIV_CATEGORY = "quant-ph"  # ã‚«ãƒ†ã‚´ãƒª (quant-ph, cs.AI, cs.LG ãªã©)
TOP_N_PAPERS = 10  # æŠ•ç¨¿ã™ã‚‹è«–æ–‡æ•°
SUMMARY_LANGUAGE = "ja"  # è¦ç´„è¨€èª (ja=æ—¥æœ¬èª, en=è‹±èª)


# ===== Scirateãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰è«–æ–‡ã‚’å–å¾— =====
def get_top_papers_from_scirate(category: str, top_n: int = 10) -> List[Dict]:
    """
    Scirateã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰ã€scitesé †ã®è«–æ–‡ã‚’å–å¾—
    """
    print(f"ğŸ“š Scirate {category}ã‚«ãƒ†ã‚´ãƒªã®ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰è«–æ–‡ã‚’å–å¾—ä¸­...")
    
    url = f"https://scirate.com/arxiv/{category}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        
        if response.status_code != 200:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: Scirateã‹ã‚‰ã®å–å¾—ã«å¤±æ•— (status: {response.status_code})")
            return []
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        papers = []
        
        # paperlist â†’ ul.papers ã‚’æ¢ã™
        paperlist = soup.find('div', class_='paperlist')
        
        if not paperlist:
            print("âŒ ã‚¨ãƒ©ãƒ¼: paperlistè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        papers_ul = paperlist.find('ul', class_='papers')
        
        if not papers_ul:
            print("âŒ ã‚¨ãƒ©ãƒ¼: ul.papersè¦ç´ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # å„è«–æ–‡è¦ç´ ï¼ˆdiv.rowï¼‰ã‚’å–å¾—
        paper_rows = papers_ul.find_all('div', class_='row')
        
        print(f"ğŸ” {len(paper_rows)}ä»¶ã®è«–æ–‡ã‚’ç™ºè¦‹")
        
        for paper_row in paper_rows:
            try:
                # arXiv IDã‚’å–å¾—ï¼ˆdiv.uidå†…ï¼‰
                uid_elem = paper_row.find('div', class_='uid')
                if not uid_elem:
                    continue
                
                uid_text = uid_elem.get_text(strip=True)
                # arXiv IDã‚’æŠ½å‡ºï¼ˆä¾‹ï¼šarXiv:2511.13560v1 â†’ 2511.13560ï¼‰
                arxiv_match = re.search(r'arXiv:(\d{4}\.\d{4,5})', uid_text)
                if not arxiv_match:
                    continue
                
                arxiv_id = arxiv_match.group(1)
                
                # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
                title_elem = paper_row.find('div', class_='title')
                if title_elem:
                    title_link = title_elem.find('a')
                    title = title_link.get_text(strip=True) if title_link else title_elem.get_text(strip=True)
                else:
                    title = "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜"
                
                # Scitesæ•°ã‚’å–å¾—
                scites = 0
                scites_count_div = paper_row.find('div', class_='scites-count')
                if scites_count_div:
                    # scites-count divå†…ã®buttonã‚’æ¢ã™
                    count_button = scites_count_div.find('button', class_='count')
                    if count_button:
                        scites_text = count_button.get_text(strip=True)
                        try:
                            scites = int(scites_text)
                        except ValueError:
                            scites = 0
                
                # è‘—è€…ã‚’å–å¾—
                authors = []
                authors_elem = paper_row.find('div', class_='authors')
                if authors_elem:
                    # è‘—è€…ãƒªãƒ³ã‚¯ã‚’å–å¾—
                    author_links = authors_elem.find_all('a')
                    for link in author_links:
                        author_name = link.get_text(strip=True).rstrip(',')
                        if author_name:
                            authors.append(author_name)
                
                papers.append({
                    'arxiv_id': arxiv_id,
                    'title': title,
                    'scites': scites,
                    'authors': authors,
                    'url': f"https://arxiv.org/abs/{arxiv_id}",
                    'scirate_url': f"https://scirate.com/arxiv/{arxiv_id}",
                    'abstract': None
                })
            
            except Exception as e:
                print(f"âš ï¸ è«–æ–‡ã®è§£æã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        # Scitesé †ã«ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
        papers.sort(key=lambda x: x['scites'], reverse=True)
        
        print(f"âœ… {len(papers)}ä»¶ã®è«–æ–‡ã‚’å–å¾—ã—ã¾ã—ãŸ")
        
        # ä¸Šä½10ä»¶ã‚’è¡¨ç¤º
        if papers:
            print(f"\nğŸ“Š Scitesæ•°ä¸Šä½{min(10, len(papers))}ä»¶:")
            for i, paper in enumerate(papers[:10], 1):
                print(f"  {i}. [{paper['scites']:3d} scites] {paper['arxiv_id']} - {paper['title'][:50]}...")
        
        return papers[:top_n]
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return []


# ===== è«–æ–‡ã®è©³ç´°æƒ…å ±ã‚’è£œå®Œ =====
def enrich_papers_with_abstracts(papers: List[Dict]) -> List[Dict]:
    """
    å„è«–æ–‡ã®Abstractã‚’arXiv APIã‹ã‚‰å–å¾—
    """
    print(f"\nğŸ“– å„è«–æ–‡ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ä¸­...")
    
    for i, paper in enumerate(papers, 1):
        print(f"   [{i}/{len(papers)}] {paper['arxiv_id']} ã®æƒ…å ±ã‚’å–å¾—ä¸­...")
        
        # arXiv APIã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
        base_url = "http://export.arxiv.org/api/query"
        params = {
            "id_list": paper['arxiv_id'],
            "max_results": 1
        }
        headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; ScirateBot/1.0)'
        }
        
        try:
            response = requests.get(base_url, params=params, headers=headers, timeout=10)
            
            if response.status_code == 200:
                root = ET.fromstring(response.content)
                ns = {'atom': 'http://www.w3.org/2005/Atom'}
                
                entry = root.find('atom:entry', ns)
                if entry:
                    # Abstract
                    abstract_elem = entry.find('atom:summary', ns)
                    if abstract_elem is not None:
                        paper['abstract'] = abstract_elem.text.strip().replace('\n', ' ')
                    
                    # ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆScirateã‹ã‚‰æ­£ã—ãå–ã‚Œãªã‹ã£ãŸå ´åˆï¼‰
                    if paper['title'] == "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜":
                        title_elem = entry.find('atom:title', ns)
                        if title_elem is not None:
                            paper['title'] = title_elem.text.strip().replace('\n', ' ')
                    
                    # è‘—è€…ï¼ˆScirateã‹ã‚‰å–ã‚Œãªã‹ã£ãŸå ´åˆï¼‰
                    if not paper['authors']:
                        authors = []
                        for author in entry.findall('atom:author', ns):
                            name = author.find('atom:name', ns)
                            if name is not None:
                                authors.append(name.text)
                        paper['authors'] = authors
        
        except Exception as e:
            print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
        
        time.sleep(1)  # arXiv APIã¸ã®è² è·ã‚’é¿ã‘ã‚‹
    
    print("âœ… è©³ç´°æƒ…å ±å–å¾—å®Œäº†")
    return papers


# ===== Claude APIã§è¦ç´„ã‚’ç”Ÿæˆ =====
def generate_summary(title: str, abstract: str, language: str = "ja") -> str:
    """
    Claude APIã‚’ä½¿ã£ã¦è«–æ–‡ã‚’2-3æ–‡ã§è¦ç´„
    """
    print(f"ğŸ¤– è¦ç´„ç”Ÿæˆä¸­: {title[:40]}...")
    
    if not abstract:
        return "AbstractãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    
    url = "https://api.anthropic.com/v1/messages"
    headers = {
        "x-api-key": ANTHROPIC_API_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
    }
    
    if language == "ja":
        prompt = f"""ä»¥ä¸‹ã®è«–æ–‡ã‚’2-3æ–‡ã®æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯æ®‹ã—ã¤ã¤ã€ä½•ã‚’ç ”ç©¶ã—ãŸã‹ãŒåˆ†ã‹ã‚‹ã‚ˆã†ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}

è¦æ—¨: {abstract}

è¦ç´„:"""
    else:
        prompt = f"""Summarize the following paper in 2-3 sentences. Keep technical terms and explain what was studied.

Title: {title}

Abstract: {abstract}

Summary:"""
    
    data = {
        "model": "claude-sonnet-4-20250514",
        "max_tokens": 300,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            summary = result['content'][0]['text'].strip()
            return summary
        else:
            print(f"âš ï¸ è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼ (status: {response.status_code})")
            return "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    
    except Exception as e:
        print(f"âš ï¸ è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"


# ===== Discordã«æŠ•ç¨¿ =====
def post_to_discord(papers: List[Dict], language: str = "ja"):
    """
    è«–æ–‡ãƒªã‚¹ãƒˆã‚’Discordã«æŠ•ç¨¿
    """
    print(f"\nğŸ“¤ Discordã«æŠ•ç¨¿ä¸­...")
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆSciRateã®URLã‚’å«ã‚€ï¼‰
    today_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    if language == "ja":
        header = f"## ğŸ“Š {today_str} ã® quant-ph äººæ°—è«–æ–‡ Top {len(papers)}\n\nğŸ”— **SciRate**: https://scirate.com/?range=1\n"
    else:
        header = f"## ğŸ“Š Top {len(papers)} quant-ph Papers - {datetime.now().strftime('%Y-%m-%d')}\n\nğŸ”— **SciRate**: https://scirate.com/?range=1\n"
    
    message = {
        "content": header
    }
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æŠ•ç¨¿
    try:
        response = requests.post(DISCORD_WEBHOOK_URL, json=message, timeout=10)
        if response.status_code != 204:
            print(f"âŒ DiscordæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼ (status: {response.status_code})")
            return
    except Exception as e:
        print(f"âŒ DiscordæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    time.sleep(1)
    
    # å„è«–æ–‡ã‚’æŠ•ç¨¿
    for i, paper in enumerate(papers, 1):
        # è¦ç´„ã‚’ç”Ÿæˆ
        summary = generate_summary(paper['title'], paper.get('abstract', ''), language)
        
        # è‘—è€…ãƒªã‚¹ãƒˆ
        if paper['authors']:
            authors_str = ", ".join(paper['authors'][:3])
            if len(paper['authors']) > 3:
                authors_str += " et al."
        else:
            authors_str = "è‘—è€…æƒ…å ±ãªã—"
        
        # Discordãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
        embed = {
            "embeds": [{
                "title": f"{i}. {paper['title']}",
                "url": paper['url'],
                "description": f"**ğŸ“ è¦ç´„**\n{summary}\n\n**ğŸ‘¥ è‘—è€…:** {authors_str}\n**â­ Scites:** {paper['scites']}",
                "color": 5814783,
                "footer": {
                    "text": f"arXiv: {paper['arxiv_id']}"
                },
                "fields": [
                    {
                        "name": "ğŸ”— ãƒªãƒ³ã‚¯",
                        "value": f"[arXiv]({paper['url']}) | [SciRate]({paper['scirate_url']})",
                        "inline": False
                    }
                ]
            }]
        }
        
        try:
            response = requests.post(DISCORD_WEBHOOK_URL, json=embed, timeout=10)
            
            if response.status_code == 204:
                print(f"âœ… {i}ä»¶ç›®ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸ: {paper['title'][:50]}...")
            else:
                print(f"âš ï¸ {i}ä»¶ç›®ã®æŠ•ç¨¿ã«å¤±æ•— (status: {response.status_code})")
        except Exception as e:
            print(f"âš ï¸ {i}ä»¶ç›®ã®æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        time.sleep(2)
    
    print(f"\nğŸ‰ å®Œäº†ï¼{len(papers)}ä»¶ã®è«–æ–‡ã‚’Discordã«æŠ•ç¨¿ã—ã¾ã—ãŸ")


# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
def main():
    print("=" * 60)
    print("ğŸš€ Scirate Discord Bot èµ·å‹•")
    print("=" * 60)
    
    # 1. Scirateãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰è«–æ–‡ã‚’å–å¾—
    papers = get_top_papers_from_scirate(ARXIV_CATEGORY, TOP_N_PAPERS)
    
    if not papers:
        print("âŒ è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    print(f"\nğŸ“‹ æŠ•ç¨¿ã™ã‚‹è«–æ–‡ï¼ˆTop {len(papers)}ï¼‰:")
    for i, paper in enumerate(papers, 1):
        print(f"  {i}. [{paper['scites']} scites] {paper['arxiv_id']} - {paper['title'][:60]}...")
    
    # 2. å„è«–æ–‡ã®Abstractã‚’å–å¾—
    papers = enrich_papers_with_abstracts(papers)
    
    # 3. Discordã«æŠ•ç¨¿
    post_to_discord(papers, SUMMARY_LANGUAGE)
    
    print("\n" + "=" * 60)
    print("âœ¨ ã™ã¹ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
